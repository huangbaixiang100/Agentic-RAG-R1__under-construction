project:
  name: "xiaobeir1"
  description: "under-construction"

experiment:
  name: "qwen2.5-32b-medqa-4GPU"  # 实验名称，对应 experiments/ 下的目录
  random_seed: 42

model:
  name: "Qwen/Qwen2.5-0.5B-Instruct"
  # name: "Qwen/Qwen2.5-7B-Instruct"
  # name: "Qwen/Qwen2.5-14B-Instruct"
  # name: "Qwen/Qwen2.5-32B-Instruct"
  torch_dtype: "bfloat16"
  device_map: null

dataset:
  name: "medqa"
  # name: "medmcqa"
  num_eval: 1000

training:
  continue_training: false
  current_step: 0

  use_lora: true
  use_qlora: false
  batch_size: 1
  learning_rate: 0.000005
  num_iterations: 2 # epoch
  steps_per_iteration: 100 # in one epoch
  save_interval: 5 # steps

  generation:
    num_generations: 4
    max_new_tokens: 200
    max_length_for_gather: 100000
    max_generate_iterations: 3
    temperature: 0.7
    do_sample: True
  
  optimizer:
    beta: 0.04
    mu: 1
    epsilon: 0.1

lora:
  r: 8
  lora_alpha: 32
  target_modules:
    - "q_proj"    # qwen
    - "v_proj"    # qwen
  lora_dropout: 0.1
  bias: "none"
  task_type: "CAUSAL_LM"

qlora:
  load_in_4bit: true
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_use_double_quant: true
  bnb_4bit_quant_storage: "bfloat16"